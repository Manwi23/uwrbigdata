\documentclass[11pt]{article}
\input{header.tex}

\newcommand{\E}{{\mathbb E}}
\DeclareMathOperator{\var}{Var}

\begin{document}

\lecture{4: Point queries, heavy hitters}{ 23/03/2022}

\section{Finding frequent elements}
\subsection{Majority elements \cite{DBLP:conf/birthday/Moore91}}
\begin{definition}
An element of a multiset $X$, $|X| = n$ is called a \emph{majority element} if it occurs more than $\frac{n}{2}$ times.
\end{definition}
We derive algorithm for finding majority element in 2-passes over the input. An useful fact:
\begin{lemma}
If $t$ is the majority element of $X$, and for some $x, y \in X$ we have $x \neq y$, then $t$ is the majority element of $X \setminus \{x, y\}$.
\end{lemma}
We can derive an algorithm utilizing this fact (this describes first pass, which returns a candidate for majority element).
\begin{verbatim}
s = anything
c = 0
for x in X:
    if x == s:
        c++
    else if c == 0:
        x = s
        c = 1
    else:
        c--
return s
\end{verbatim}
If $X$ contains a majority element it will be returned, otherwise we get random garbage. Second pass is just to verify if candidate is actually a majority element.
\subsection{$\frac{1}{k}$-heavy elements}
\begin{definition}
An element of a multiset $X$, $|X|=n$, is called $\frac{1}{k}$-heavy if it occurs at least $\frac{n}{k}$ times.
\end{definition}
\begin{lemma}
If $t$ is an $\frac{1}{k}$-heavy element of $X$,and $x_1, ..., x_k \in X$ are pairwise distinct, then $t$ is a $\frac{1}{k}$-heavy element of $X \setminus \{x_1, ..., x_k \}$.
\end{lemma}
We can again derive an algorithm:
\begin{itemize}
\item Summary of a stream: a multiset $S$ (represented for example as a collection of pairs $(x_i, c_i)$)
\item Invariant: $\#distinct(S) \le k$
\item Insert: add the element to $S$, then run the pruning step
\item Pruning: while $\#distinct(S) > k$: remove from $S$ one copy of each element in $S$
\end{itemize}
At the end the summary will contain all heavy hitters but it may also contain other elements - we need a second pass to check. This algorithm is deterministic and the summaries are mergeable.
\section{$L_p$ point queries, $L_p$ heavy hitters}
Assume turnstile streaming model, we maintain vector $x$ under updates. Choose a norm $L_p$.
\begin{itemize}
\item \textbf{Point query}: for a given $i$ return $x_i \pm \varepsilon |x|_p$
\item \textbf{Heavy hitters}: $HH_\varepsilon(x) = \{ i: |x_i| \ge \varepsilon |x|_p\}$. Output $L$ such that:
\begin{enumerate}
\item $HH_\varepsilon(x) \subseteq L \subseteq HH_{\varepsilon'}(x)$ for some $\varepsilon' < \varepsilon$, or
\item $HH_\varepsilon(x) \subseteq L$ and $|L| = O(\frac{1}{\varepsilon^p})$ (intuition: $|HH_\varepsilon(x)| \le \frac{1}{\varepsilon^p}$).
\end{enumerate}
\end{itemize}
\begin{observation}
\textbf{Roughly}, if we can solve one of these problems, then we can also solve the other (they reduce to each other).
\end{observation}
\section{CountMin \cite{DBLP:conf/latin/CormodeM04}}
\subsection{Point queries}
Assume $\forall_i x_i \ge 0$. Let $h:[n]\to[t]$ be a 2-wise independent hashing function for $t=\frac{2}{\varepsilon}$. Maintain an array $Z[1..t]$ such that $$Z[j]=\sum_{i: h(i) = j} x_i$$
\begin{itemize}
\item $\text{Update}(i, \Delta)$: $Z[h(i)] \leftarrow Z[h(i)] + \Delta$
\item $\text{Query}(i)$: output $x'_i = Z[h(i)]$
\end{itemize}
Properties of queries:
\begin{enumerate}
\item $x'_i \ge x_i$
\item $\E[x'_i - x_i] = \sum_{j \neq i} \Pr[h(j) = h(i)] \cdot x_j \le \frac{1}{t}|x|_1 = \frac{\varepsilon}{2}|x|_1$
\end{enumerate}
From Markov's inequality: $$\Pr[x’_i - x_i \ge \varepsilon |x|_1] \le \frac{1}{2}$$
so we get an $L_1$ guarantee.

We can now derive the actual algorithm: we repeat the process independently $r = \log(\delta^{-1})$ times, using independent hashing functions $h_1, ..., h_r:[n]\rightarrow[t]$. We take the minimum of query results as the answer:
\begin{itemize}
\item $\text{Update}(i, \Delta)$: $\forall_{j \in [r]} Z[j][h_j(i)] \leftarrow Z[j][h_j(i)] + \Delta$
\item $\text{Query}(i)$: output $x'_i = \min_j Z[j][h_j(i)]$
\end{itemize}
We now get: $$P(x’_i - x_i \ge \varepsilon|x|_1) \le \left(\frac{1}{2}\right)^r = \delta$$
Recall we assumed $\forall_i x_i \ge 0$. For the general case replace minimum with median, and take $t = \frac{3}{\varepsilon}$. Finally, space complexity: $O\left(\frac{\log \delta^{-1}}{\varepsilon}\right)$ words  and time complexity: $O(\log \delta^{-1})$ per update/query.
\subsection{Heavy hitters}
\subsubsection{Generic transformation}
This method only works in the semi-turnstile model.
\begin{itemize}
\item Maintain $|x|$ from sketch, keep heavy hitters in a priority queue
\item On update run a point query, if $x_i$ is a heavy hitter - insert it into the queue or update its weight
\item Whenever the element with lowest weight gets below the $\varepsilon|x|$ threshold, remove it from the queue
\end{itemize}
\subsubsection{Our case}
We construct a binary search tree with $O(\log n)$ levels and $n$ nodes in the lowest level. Each node represents the sum of values from an interval of the form $[a2^b+1, (a+1)2^b]$. Each level is implemented as a separate CountMin structure. We perform queries recursively descending only into nodes where the output is at least $\varepsilon|x|_1$. Since there are only $\frac{1}{\varepsilon}$ such nodes at each level, we can apply the union bound $\delta' = \frac{\delta}{2\log n}$.
\section{CountSketch \cite{DBLP:conf/icalp/CharikarCF02}}
Let $h_1, ..., h_r: [n] \rightarrow [t]$ and $s_1, ..., s_r: [n] \rightarrow \{-1, 1\}$ be 2-wise independent hashing functions.
\begin{itemize}
\item $\text{Update}(i, \Delta)$: $\forall_{j \in [r]} Z[j][h_j(i)] \leftarrow Z[j][h_j(i)] + s_j(i)\cdot \Delta$ 
\item $\text{Query}(i)$: output $x'_i = median_j Z[j][h_j(i)]$
\end{itemize}
For a fixed $j$:
$$ \E[ (x_i - Z[j][h_j(i)])^2 ] = \E\left[ \left(\sum_{k \neq i} \Pr[h_j(k)=h_j(i)] x_k s_j(k)\right)^2 \right] = \sum_{k \neq i} \frac{1}{t} x_k^2 
\le \frac{1}{t}|x|_2^2 $$
$$\Pr\left[ (x_i - Z[j][h_j(i)])^2 > \frac{3}{t} |x|_2^2 \right] < \frac{1}{3}$$
$$\Pr\left[ \big|x_i - Z[j][h_j(i)]\big| > \sqrt{\frac{3}{t}} |x|_2 \right] < \frac{1}{3} $$
For $t = O\left(\frac{1}{\varepsilon^2}\right)$ we get
$$\Pr\left[ \big|x_i - Z[j][h_j(i)]\big| > \varepsilon|x|_2\right] < \frac{1}{3}$$
so we get an $L_2$ norm guarantee. We then use the median with $r = O(\log\delta^{-1})$ to get $1-\delta$ correctness.


\bibliographystyle{alpha}
\bibliography{bib}
\end{document}

